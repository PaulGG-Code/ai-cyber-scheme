import streamlit as st
import pandas as pd
import re
from langchain_openai import ChatOpenAI
from langchain_experimental.agents import create_pandas_dataframe_agent

# -------------------------------------------------------------------
# 1. Utility functions for building a hierarchical tree from ref_id
# -------------------------------------------------------------------

def natural_sort_key(ref_id: str):
    """
    A 'natural' sort key that splits the string into digit and non-digit chunks.
    Each chunk is turned into a 2-element tuple:
      - (0, 'lowercased_text') for text chunks
      - (1, integer) for numeric chunks
    Example: "Article 10" -> [ (0, 'article '), (1, 10) ]
    This avoids comparing str vs. int, preventing TypeError.
    """
    # Split ref_id by numeric groups, e.g. "Article 10" -> ["Article ", "10", ""]
    parts = re.split(r'(\d+)', ref_id)

    sort_key = []
    for part in parts:
        # Skip empty strings (e.g. trailing splits)
        if not part:
            continue
        if part.isdigit():
            # numeric chunk
            sort_key.append((1, int(part)))
        else:
            # text chunk (case-insensitive)
            sort_key.append((0, part.lower()))
    return sort_key

def get_parent_ref_id(ref_id: str) -> str:
    """
    Given a string like '1.2.3', return '1.2'.
    If there's no parent, return '' (empty string).
    """
    parts = ref_id.split(".")
    if len(parts) > 1:
        return ".".join(parts[:-1])
    else:
        return ""

def build_tree(df: pd.DataFrame) -> dict:
    """
    Build a tree (dict) from DataFrame rows with 'ref_id', 'name', 'description'.
    """
    tree_nodes = {}
    for _, row in df.iterrows():
        ref_id = str(row["ref_id"])
        tree_nodes[ref_id] = {
            "name": row.get("name", "Unnamed"),
            "description": row.get("description", "No description available."),
            "children": {}
        }

    # Link child nodes to parents
    roots = {}
    for ref_id, node_data in tree_nodes.items():
        parent_id = get_parent_ref_id(ref_id)
        if parent_id == "":
            # Top-level node
            roots[ref_id] = node_data
        else:
            # Child node
            parent_node = tree_nodes.get(parent_id)
            if parent_node:
                parent_node["children"][ref_id] = node_data
            else:
                # Parent not found => treat as root
                roots[ref_id] = node_data

    return roots

def render_tree(tree_dict: dict, indent: int = 0) -> str:
    """
    Recursively render the tree as an indented bullet list in Markdown,
    using the natural_sort_key to compare ref_ids.
    """
    lines = []
    indent_spaces = " " * indent

    def sort_key(item):
        ref_id = item[0]
        return natural_sort_key(ref_id)

    # Sort the child dictionary items by the natural key
    for ref_id, node_data in sorted(tree_dict.items(), key=sort_key):
        name = node_data["name"]
        description = node_data["description"]

        lines.append(f"{indent_spaces}- **{ref_id}**: {name}")
        desc_indent_spaces = " " * (indent + 4)
        lines.append(f"{desc_indent_spaces}{description}")

        if node_data["children"]:
            child_output = render_tree(node_data["children"], indent + 4)
            lines.append(child_output)

    return "\n".join(lines)

def show_ai_act_hierarchy(df: pd.DataFrame):
    """
    Show the AI Act data in a hierarchical view, using *natural sort* 
    so numeric parts of ref_id are sorted in ascending numerical order.
    """
    if df.empty:
        st.warning("No AI Act data available to display.")
        return

    st.subheader("AI Act Hierarchical View (Natural Ordering)")

    tree = build_tree(df)

    # Sort top-level nodes by the natural key
    def sort_key(item):
        return natural_sort_key(item[0])

    for root_id, root_data in sorted(tree.items(), key=sort_key):
        with st.expander(f"{root_id}: {root_data['name']}", expanded=False):
            st.write(root_data["description"])
            if root_data["children"]:
                subtree_markdown = render_tree(root_data["children"], indent=0)
                st.markdown(subtree_markdown, unsafe_allow_html=True)

# -------------------------------------------------------------------
# 2. Data Loading and Preprocessing
# -------------------------------------------------------------------
def load_data(filepath: str) -> dict:
    excel_data = pd.ExcelFile(filepath)
    return {sheet: excel_data.parse(sheet) for sheet in excel_data.sheet_names}

def preprocess_cra_data(dataframes: dict) -> pd.DataFrame:
    cra_df = dataframes.get("CRA", pd.DataFrame())
    if not cra_df.empty:
        cra_df = cra_df.rename(columns=str.lower)
        required_cols = {"ref_id", "depth", "description", "name"}
        missing_cols = required_cols - set(cra_df.columns)
        for col in missing_cols:
            cra_df[col] = None
        cra_df["description"].fillna("No description available.", inplace=True)
        cra_df["name"].fillna("Unnamed Category", inplace=True)
        cra_df["ref_id"] = cra_df["ref_id"].astype(str)
    return cra_df

def preprocess_masvs_data(dataframes: dict) -> pd.DataFrame:
    masvs_df = dataframes.get("masvs", pd.DataFrame())
    if not masvs_df.empty:
        if "description" not in masvs_df.columns:
            masvs_df["description"] = "No description available."
        masvs_df["description"].fillna("No description available.", inplace=True)
    return masvs_df

def preprocess_ai_act_data(dataframes: dict) -> pd.DataFrame:
    ai_act_df = dataframes.get("AI ACT", pd.DataFrame())
    if not ai_act_df.empty:
        ai_act_df = ai_act_df.rename(columns=str.lower)
        required_cols = {"depth", "ref_id", "name", "description"}
        missing_cols = required_cols - set(ai_act_df.columns)
        for col in missing_cols:
            ai_act_df[col] = None
        ai_act_df["description"].fillna("No description available.", inplace=True)
        ai_act_df["name"].fillna("Unnamed Section", inplace=True)
        ai_act_df["ref_id"] = ai_act_df["ref_id"].astype(str)
    return ai_act_df

# -------------------------------------------------------------------
# 3. Fetching Hierarchies for CRA
# -------------------------------------------------------------------
def fetch_hierarchy(df: pd.DataFrame, main_ref: str) -> pd.DataFrame:
    if "ref_id" not in df.columns or "depth" not in df.columns:
        raise ValueError("The DataFrame is missing 'ref_id' or 'depth'.")
    df["ref_id"] = df["ref_id"].astype(str)
    subset = df[df["ref_id"].str.startswith(main_ref, na=False)]
    subset = subset.sort_values(by="ref_id")
    return subset

# -------------------------------------------------------------------
# 4. LangChain Agent
# -------------------------------------------------------------------
def create_agent(df: pd.DataFrame, openai_api_key: str):
    llm = ChatOpenAI(
        temperature=0,
        openai_api_key=openai_api_key,
        model_name="gpt-3.5-turbo"
    )
    return create_pandas_dataframe_agent(llm, df, verbose=False, allow_dangerous_code=True)

# -------------------------------------------------------------------
# 5. Main App
# -------------------------------------------------------------------
def main():
    st.set_page_config(page_title="Excel AI Agent", layout="wide")

    st.sidebar.title("Configuration")
    openai_api_key = st.sidebar.text_input("OpenAI API Key", type="password")

    dataset_options = {
        "OWASP MASVS v2.1.0": "owasp-masvs-v2.1.0.xlsx",
        "CRA Regulation Annexes": "cra-regulation-annexes.xlsx",
        "AI Act Directive": "AI-act.xlsx"
    }
    dataset_choice = st.sidebar.selectbox("Select a Dataset", list(dataset_options.keys()))
    data_file = dataset_options.get(dataset_choice)

    st.title("Excel-Powered AI Agent")
    st.write(f"Ask questions about the data in **{dataset_choice}**. Provide your OpenAI API key in the sidebar.")

    try:
        dataframes = load_data(data_file)
        if dataset_choice == "OWASP MASVS v2.1.0":
            df = preprocess_masvs_data(dataframes)
        elif dataset_choice == "CRA Regulation Annexes":
            df = preprocess_cra_data(dataframes)
        elif dataset_choice == "AI Act Directive":
            df = preprocess_ai_act_data(dataframes)
        else:
            df = pd.DataFrame()

        st.write(f"Loaded dataset: **{dataset_choice}** with sheets: {list(dataframes.keys())}")
    except Exception as e:
        st.error(f"Failed to load the dataset **{dataset_choice}**. Error: {e}")
        return

    if df.empty:
        st.error(f"The data for **{dataset_choice}** could not be loaded or is empty.")
        return

    # ------------------------------------------------------------------
    # CRA-specific hierarchical filtering
    # ------------------------------------------------------------------
    if dataset_choice == "CRA Regulation Annexes":
        main_ref = st.text_input("Enter a main requirement ID (e.g., '1', '1.1'):", "").strip()
        if main_ref:
            try:
                filtered_hierarchy = fetch_hierarchy(df, main_ref)
                if not filtered_hierarchy.empty:
                    st.write(f"Requirements under '{main_ref}':")
                    st.write("**Full Description of Requirements:**")
                    for _, row in filtered_hierarchy.iterrows():
                        st.markdown(f"**{row['ref_id']}**: {row['description']}")
                    st.table(filtered_hierarchy)
                else:
                    st.warning(f"No requirements found for '{main_ref}'.")
            except Exception as e:
                st.error(f"Error fetching hierarchy: {e}")

    # ------------------------------------------------------------------
    # AI Act-specific hierarchical filtering + NATURAL Tree View
    # ------------------------------------------------------------------
    if dataset_choice == "AI Act Directive":
        depth = st.number_input("Enter depth level (e.g., 1, 2):", min_value=1, step=1)
        if depth:
            try:
                filtered = df[df["depth"] == depth].sort_values(by="ref_id")
                if not filtered.empty:
                    st.write(f"Sections at depth **{depth}**:")
                    st.table(filtered[["ref_id", "name", "description"]])
                else:
                    st.warning(f"No sections found for depth '{depth}'.")
            except Exception as e:
                st.error(f"Error fetching hierarchy by depth: {e}")

        # Show the NATURAL-ORDER hierarchical view
        show_ai_act_hierarchy(df)

    # (Optional) MASVS or other datasets remain as-is
    # ------------------------------------------------

    # LangChain agent for user queries
    if openai_api_key:
        agent = create_agent(df, openai_api_key)
        user_question = st.text_input("Ask a question about the data:", "")
        if st.button("Ask"):
            if not user_question.strip():
                st.warning("Please enter a valid question.")
            else:
                with st.spinner("Generating answer..."):
                    try:
                        answer = agent.invoke(user_question)
                        if isinstance(answer, pd.DataFrame):
                            st.markdown(answer.to_markdown(index=False))
                        elif isinstance(answer, dict) and "output" in answer:
                            st.markdown(answer["output"])
                        else:
                            st.markdown(answer)
                    except Exception as e:
                        st.error(f"Error: {e}")
    else:
        st.warning("Please enter your OpenAI API key in the sidebar.")

if __name__ == "__main__":
    main()